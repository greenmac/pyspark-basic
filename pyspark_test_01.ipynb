{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-F23MUC7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['tom', 10], ['nick', 15], ['juil', 14], ['nick', 20], ['david', 15], ['tom', 40]]\n",
    "df = pd.DataFrame(data, columns = ['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pyspark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|  tom| 10|\n",
      "| nick| 15|\n",
      "| juil| 14|\n",
      "| nick| 20|\n",
      "|david| 15|\n",
      "|  tom| 40|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'bigint')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "pyspark_df = pyspark_df.withColumn('new_col_1', lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| Name|Age|new_col_1|\n",
      "+-----+---+---------+\n",
      "|  tom| 10|        1|\n",
      "| nick| 15|        1|\n",
      "| juil| 14|        1|\n",
      "| nick| 20|        1|\n",
      "|david| 15|        1|\n",
      "|  tom| 40|        1|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df = pyspark_df.withColumn('new_col_2', pyspark_df.Age+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+---------+\n",
      "| Name|Age|new_col_1|new_col_2|\n",
      "+-----+---+---------+---------+\n",
      "|  tom| 10|        1|       11|\n",
      "| nick| 15|        1|       16|\n",
      "| juil| 14|        1|       15|\n",
      "| nick| 20|        1|       21|\n",
      "|david| 15|        1|       16|\n",
      "|  tom| 40|        1|       41|\n",
      "+-----+---+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---------+---------+\n",
      "|Name|Age|new_col_1|new_col_2|\n",
      "+----+---+---------+---------+\n",
      "|nick| 15|        1|       16|\n",
      "|nick| 20|        1|       21|\n",
      "+----+---+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.filter(pyspark_df.Name == 'nick').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark_df.filter(pyspark_df.Name == 'nick').collect()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+---------+\n",
      "| Name|Age|new_col_1|new_col_2|\n",
      "+-----+---+---------+---------+\n",
      "|  tom| 10|        1|       11|\n",
      "| nick| 15|        1|       16|\n",
      "| juil| 14|        1|       15|\n",
      "| nick| 20|        1|       21|\n",
      "|david| 15|        1|       16|\n",
      "|  tom| 40|        1|       41|\n",
      "+-----+---+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| Name|\n",
      "+-----+\n",
      "|david|\n",
      "| nick|\n",
      "|  tom|\n",
      "| juil|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.select('Name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "| Name|avg(Age)|\n",
      "+-----+--------+\n",
      "|david|    15.0|\n",
      "| nick|    17.5|\n",
      "|  tom|    25.0|\n",
      "| juil|    14.0|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "pyspark_df.groupby('Name').agg(mean('Age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['nick', 80], ['juil', 70], ['david', 90], ['tom', 60]]\n",
    "score = pd.DataFrame(data, columns = ['Name', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nick</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juil</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>david</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tom</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Score\n",
       "0   nick     80\n",
       "1   juil     70\n",
       "2  david     90\n",
       "3    tom     60"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.DataFrame(score)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['nick', 80], ['juil', 70], ['david', 90], ['tom', 60]]\n",
    "score = pd.DataFrame(data, columns = ['Name', 'Score'])\n",
    "pyspark_score = spark.createDataFrame(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| Name|Score|\n",
      "+-----+-----+\n",
      "| nick|   80|\n",
      "| juil|   70|\n",
      "|david|   90|\n",
      "|  tom|   60|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_score.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+---------+-----+\n",
      "| Name|Age|new_col_1|new_col_2|Score|\n",
      "+-----+---+---------+---------+-----+\n",
      "|david| 15|        1|       16|   90|\n",
      "| nick| 15|        1|       16|   80|\n",
      "| nick| 20|        1|       21|   80|\n",
      "|  tom| 10|        1|       11|   60|\n",
      "|  tom| 40|        1|       41|   60|\n",
      "| juil| 14|        1|       15|   70|\n",
      "+-----+---+---------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df.join(pyspark_score, 'Name', how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
